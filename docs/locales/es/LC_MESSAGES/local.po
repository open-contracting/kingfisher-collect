# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, Open Contracting Partnership
# This file is distributed under the same license as the OCDS Kingfisher
# Collect package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: OCDS Kingfisher Collect \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-02-25 20:22-0300\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../local.rst:2
msgid "Download data to your computer"
msgstr ""

#: ../../local.rst:4
msgid ""
"This page will guide you through installing Kingfisher Collect and using "
"it to collect data from data sources."
msgstr ""

#: ../../local.rst:9
msgid "Install Kingfisher Collect"
msgstr ""

#: ../../local.rst:11
msgid ""
"To use Kingfisher Collect, you need access to a `Unix-like shell "
"<https://en.wikipedia.org/wiki/Shell_(computing)>`__ (some are available "
"for Windows). `Git <https://git-scm.com>`__ and `Python "
"<https://www.python.org>`__ (version 3.6 or greater) must be installed."
msgstr ""

#: ../../local.rst:13
msgid "When ready, open a shell, and run:"
msgstr ""

#: ../../local.rst:21
msgid ""
"The next steps assume that you have changed to the ``kingfisher-collect``"
" directory (the ``cd`` command above)."
msgstr ""

#: ../../local.rst:26
msgid "Configure Kingfisher Collect"
msgstr ""

#: ../../local.rst:30
msgid "This step is optional."
msgstr ""

#: ../../local.rst:32
msgid ""
"To use a different directory than the default ``data`` directory to store"
" files, change the ``FILES_STORE`` variable in the "
"``kingfisher_scrapy/settings.py`` file. It can be a relative path (like "
"``data``) or an absolute path (like ``/home/user/path``)."
msgstr ""

#: ../../local.rst:41
msgid "Collect data"
msgstr ""

#: ../../local.rst:43
msgid "You're now ready to collect data!"
msgstr ""

#: ../../local.rst:45
msgid "To list the spiders, run:"
msgstr ""

#: ../../local.rst:51
msgid ""
"The spiders' names might be ambiguous. If you're unsure which spider to "
"run, you can compare their names to the list of `OCDS publishers "
"<https://www.open-contracting.org/worldwide/#/table>`__, or `contact the "
"OCDS Helpdesk <data@open-contracting.org>`__."
msgstr ""

#: ../../local.rst:53
msgid ""
"To run a spider (that is, to start a \"crawl\"), replace ``spider_name`` "
"below with the name of a spider from ``scrapy list`` above:"
msgstr ""

#: ../../local.rst:62
msgid "Download a sample"
msgstr ""

#: ../../local.rst:64
msgid ""
"To download only a sample of the available data, set the sample size with"
" the ``sample`` spider argument:"
msgstr ""

#: ../../local.rst:70
msgid "Scrapy will then output a log of its activity."
msgstr ""

#: ../../local.rst:74
msgid ""
"``_sample`` will be added to the spider's directory, e.g. ``kingfisher-"
"collect/data/zambia_sample``."
msgstr ""

#: ../../local.rst:79
msgid "Filter the data"
msgstr ""

#: ../../local.rst:81
msgid ""
"Each spider supports different filters, which you can set as spider "
"arguments. For example:"
msgstr ""

#: ../../local.rst:87
msgid "You can find which filters a spider supports on the :doc:`spiders` page."
msgstr ""

#: ../../local.rst:89
msgid ""
"Not all of an API's features are exposed by Kingfisher Collect. Each "
"spider links to its API documentation in its :ref:`metadata<spider-"
"metadata>`, where you can learn what filters the API supports. If the "
"filters are implemented as query string parameters, you can apply "
"multiple filters with, for example:"
msgstr ""

#: ../../local.rst:98
msgid "Collect data incrementally"
msgstr ""

#: ../../local.rst:100
msgid ""
"By default, ``scrapy crawl`` downloads all the data from the source. You "
"can use :ref:`spider arguments<spider-arguments>` to :ref:`filter the "
"data<filter>`, in order to only collect new data. For example, you might "
"run a first crawl to collect data until yesterday:"
msgstr ""

#: ../../local.rst:106
msgid ""
"Then, at a later date, run a second crawl to collect data from the day "
"after until yesterday:"
msgstr ""

#: ../../local.rst:112
msgid ""
"And so on. However, as you learned in :ref:`how-it-works`, each crawl "
"writes data to a separate directory. By default, this directory is named "
"according to the time at which you started the crawl. To collect the "
"incremental data into the same directory, you can take the time from the "
"first crawl's directory name, then override the time of subsequent crawls"
" with the ``crawl_time`` spider argument:"
msgstr ""

#: ../../local.rst:118
msgid ""
"If you are integrating with :doc:`Kingfisher "
"Process<kingfisher_process>`, remember to set the "
"``keep_collection_open`` spider argument, in order to not close the "
"collection when the crawl is finished:"
msgstr ""

#: ../../local.rst:127
msgid "Use a proxy"
msgstr ""

#: ../../local.rst:131
msgid ""
"This is an advanced topic. In most cases, you will not need to use this "
"feature."
msgstr ""

#: ../../local.rst:133
msgid ""
"If the data source is blocking Scrapy's requests, you might need to use a"
" proxy."
msgstr ""

#: ../../local.rst:135
msgid ""
"To use an HTTP and/or HTTPS proxy, set the ``http_proxy`` and/or "
"``https_proxy`` environment variables, and `override "
"<https://docs.scrapy.org/en/latest/topics/settings.html#command-line-"
"options>`__ the ``HTTPPROXY_ENABLED`` Scrapy setting:"
msgstr ""

#: ../../local.rst:142
msgid "Use data"
msgstr ""

#: ../../local.rst:144
msgid ""
"You should now have a crawl directory within the ``data`` directory "
"containing OCDS files. For help using data, read about `using open "
"contracting data <https://www.open-contracting.org/data/data-use/>`__."
msgstr ""

